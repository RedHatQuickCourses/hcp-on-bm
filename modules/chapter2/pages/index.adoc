= Prepare the BareMetal Node

1. Familiarize yourself with the HCP on BM architecture.
+
image::s3-fig-1.png[]
+
NOTE: Is there an SVG (or google slides) version of that diagram?
+
WARNING: write a summary of what's in there:
- DHCP services provided by libvirt on the host
- DNS zone for the mylab.com domain on the helper VM
- TFTP (PXE) services on the helper VM
- HAProxy LB services on the helper VM

2. Once the instance is up and running, ssh to the node using the private key downloaded earlier. 
+
image::s3-fig-2.jpg[]

3. The public IP of the instance can be obtained from the AWS console after clicking on the instance.
+
[source,subs="verbatim,quotes"]
--
$ ssh -i _<path to the private key>_  ec2-user@_<public ip>_
--
+
NOTE: Warn about using keep alive so the connection doesn't terminate during long-running ansible playbooks, killing the runner.
+
[source,subs="verbatim,quotes"]
--
$ ssh -o "ServerAliveInterval 30" -o "ServerAliveCountMax 120" -i _<path to the private key>_ ec2-user@_<public ip>_
--

4. Install Ansible Core and other supporting packages.
+
[source,subs="verbatim,quotes"]
--
$ sudo -i
# dnf install -y tmux waypipe
# dnf groupinstall -y "Server with GUI"
# dnf install -y ansible-core
# ansible-galaxy collection install community.libvirt
# ansible-galaxy collection install community.crypto
--

5. Setup VNC access, if you prefer it over waypipe.
+
[source,subs="verbatim,quotes"]
--
# dnf install -y tigervnc tigervnc-server
# echo ":99=vncuser" >> /etc/tigervnc/vncserver.users
# systemctl enable vncserver@:99 --now
# useradd vncuser
# su - vncuser
$ vncpasswd   # set a strong password
Would you like to enter a view-only password (y/n)? n
$ exit
--

6. Connect to the public ip of the baremetal node on port 5999 using `vncviewer` to get its graphical console. This will be required to access the Openshift console later.

.. Alternatively, you can use `waypipe` in front of your `ssh` command, instead of a VNC viewer, and start a Firefox from the shell.
+
[source,subs="verbatim,quotes"]
--
$ waypipe ssh -o "ServerAliveInterval 30" -o "ServerAliveCountMax 120" -i _<path to the private key>_ ec2-user@_<public ip>_
$ firefox &
--

7. Download latest `rhel-9.5-x86_64-kvm.qcow2` cloud image (*Red Hat Enterprise Linux 9.5 KVM Guest Image*) from the https://access.redhat.com/downloads[customer portal] and copy to the baremetal node.
+
WARNING: Make learners aware of that BEFORE starting. Not good pausing here while it downloads, 10min or more for me.
+
[ Cannot find a way of getting the download URL to use with curl directly on the EC2 instance. ]

8. Clone the git repository and move the RHEL Image to the correct directory.
+
[source,subs="verbatim,quotes"]
--
# git clone https://github.com/v2pkthakur/hcp-on-bm.git
# cd hcp-on-bm
# cp ~vncuser/Downloads/rhel-9.6-x86_64-kvm.qcow2 roles/setup-bm-host/files/
--
+
NOTE: Clone or fork the repository as part of the Quick Courses organization?

9. Explore the inventory and variables and update where required.
+
For example, if you got a newer version of RHEL9 Qcow instead of RHEL9.5, please update the `rhel9_kvm_image` variable.
+
[source,subs="verbatim,quotes"]
--
$ vi vars.yaml
...
rhel9_kvm_image: rhel-9.6-x86_64-kvm.qcow2
... 
--

10. Login on the https://console.redhat.com[Red Hat Hybrid Cloud Console] and get your organization ID, which can be obtained by clicking your name on top right.
+
image::s3-fig-3.jpg[]

11. Create an activation key from the cloud console by entering its https://console.redhat.com/insights/connector/activation-keys[Insights pages] and note down the name of the activation key.
+
Use the details from the screenshot to fill the activation key details. Make sure that you name it appropriately.
+
image::s3-fig-4.jpg[]

12. Copy your OpenShift pull secret from the cloud console by entering its https://console.redhat.com/openshift/install/pull-secret[OpenShift pages].
+
image::s3-fig-5.jpg[]

13. Configure `ansible-vault` to store your organization ID, activation keys, and OpenShift pull secret.
+
[source,subs="verbatim,quotes"]
--
# ansible-vault create vault.yaml
New Vault password:
Confirm New Vault password:
org_id: _XXXX_
activation_key: _YYYYY_
pull_secret: '_ZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZZ_'
--

14. Set up the baremetal node by running the ansible playbook.
+
[source,subs="verbatim,quotes"]
--
$ ansible-playbook -i inventory/hosts setup_bm_host.yaml --ask-vault-pass
--

15. Review key configuration settings that will affect our hosted clusters in the final activity.

.. You should have a single libvirt VM named `helper`.
+
[source,subs="verbatim,quotes"]
--
# virsh list --all
 Id   Name     State
------------------------
 1    helper   running
--

.. The libvirt default network provides fixed IP addresses, based on MAC addresses, for  six hosts, each three in a different hosted cluster. You can add more if you need.
+
[source,subs="verbatim,quotes"]
--
# virsh net-dumpxml default
<network connections='8'>
  <name>default</name>
  <uuid>467059b1-29f1-4bfc-bb9a-1b5ae26d244c</uuid>
  <forward mode='nat'>
    <nat>
      <port start='1024' end='65535'/>
    </nat>
  </forward>
  <bridge name='virbr0' stp='on' delay='0'/>
  <mac address='52:54:00:c7:82:0c'/>
  <dns>
    <forwarder domain='hub.mylab.com' addr='192.168.122.21'/>
    <forwarder domain='hcp-cluster1.mylab.com' addr='192.168.122.21'/>
    <forwarder domain='hcp-cluster2.mylab.com' addr='192.168.122.21'/>
    <forwarder domain='122.168.192.in-addr.arpa' addr='192.168.122.21'/>
  </dns>
  <ip address='192.168.122.1' netmask='255.255.255.0'>
    <dhcp>
      <host mac='52:54:00:e2:54:21' name='helper_server.hub.mylab.com' ip='192.168.122.21'/>
      <host mac='52:54:00:e2:54:30' name='bootstrap.hub.mylab.com' ip='192.168.122.30'/>
      <host mac='52:54:00:e2:54:31' name='master1.hub.mylab.com' ip='192.168.122.31'/>
      <host mac='52:54:00:e2:54:32' name='master2.hub.mylab.com' ip='192.168.122.32'/>
      <host mac='52:54:00:e2:54:33' name='master3.hub.mylab.com' ip='192.168.122.33'/>
      <host mac='52:54:00:e2:54:34' name='worker1.hub.mylab.com' ip='192.168.122.34'/>
      <host mac='52:54:00:e2:54:35' name='worker2.hub.mylab.com' ip='192.168.122.35'/>
      <host mac='52:54:00:e2:54:36' name='worker3.hub.mylab.com' ip='192.168.122.36'/>
      <host mac='52:54:00:e2:54:39' name='hublb.hub.mylab.com' ip='192.168.122.39'/>
      <host mac='52:54:00:e2:54:41' name='c1worker1.hub.mylab.com' ip='192.168.122.41'/>
      <host mac='52:54:00:e2:54:42' name='c1worker2.hub.mylab.com' ip='192.168.122.42'/>
      <host mac='52:54:00:e2:54:43' name='c1worker3.hub.mylab.com' ip='192.168.122.43'/>
      <host mac='52:54:00:e2:54:49' name='c1lb.hub.mylab.com' ip='192.168.122.49'/>
      <host mac='52:54:00:e2:54:51' name='c2worker1.hub.mylab.com' ip='192.168.122.51'/>
      <host mac='52:54:00:e2:54:52' name='c2worker2.hub.mylab.com' ip='192.168.122.52'/>
      <host mac='52:54:00:e2:54:53' name='c2worker3.hub.mylab.com' ip='192.168.122.53'/>
      <host mac='52:54:00:e2:54:59' name='c2lb.hub.mylab.com' ip='192.168.122.59'/>
      <host mac='52:54:00:e2:54:71' name='c2vbmc.hub.mylab.com' ip='192.168.122.71'/>
      <host mac='52:54:00:e2:54:81' name='aap.hub.mylab.com' ip='192.168.122.81'/>
      <bootp file='pxelinux.0' server='192.168.122.21'/>
    </dhcp>
  </ip>
</network>
--

.. It also provide for three load balancer IPs, one for the hub cluster, and two for hosted clusters. If you need more, you also need to change the HAProxy settings on the helper VM.

.. Finally, it configures Libvirt's DNS server to forward queries for the domains of the hub and two hosted clusters. [ Break the previous listing and add callouts? ]

.. Open a SSH session to the helper VM and inspect open network ports. Notice the `haproxy` and `named` daemons running, and also that Systemd will an TFTP server when there's UDP traffic to it.
+
[source,subs="verbatim,quotes"]
--
# ssh -i ~/.ssh/lab_rsa 192.168.122.21
# netstat -lntp
# systemctl status tftp.socket
# exit
--

16. Allow access to `virt-manager` from your GUI user.

.. Add either the `ec2-user` user (if using `waypipe`) of the `vncuser` user (if using a VNC viewer) to the `libvirt` group.
+
[source,subs="verbatim,quotes"]
--
# usermod -aG libvirt vncuser
# usermod -aG libvirt ec2-user
--

.. If using a VNC viewer, you must stop and restart your VNC desktop.
+
[source,subs="verbatim,quotes"]
--
# systemctl stop vncserver@:99
# systemctl start vncserver@:99
--

.. If using `waypipe`, you must close and reconnect your SSH session.

.. In either case, check that the `libvirt` group is on the environment of your GUI user.
+
[source,subs="verbatim,quotes"]
--
$ id
uid=1000(ec2-user) gid=1000(ec2-user) groups=1000(ec2-user),4(adm),190(systemd-journal),984(libvirt) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023
--
