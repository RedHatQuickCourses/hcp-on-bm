= Introduction to OpenShift HCP and the PoC Environment

////
Video segments: intro.mp4
extracted from
https://drive.google.com/file/d/1x8WS_DQjKyOW_o3T7_WM9xXAe4rLgMWt/view?usp=sharing

0:00::
Introduction to Hosted Control Planes (HCP) and typical deployment architectures.

9:43::
Planning PoC/Tests, Justification for using a single physical machine, lab architecture.

12:10::

Sample command to extract the video segment, without re-encoding:
$ ffmpeg -i rh1-otg17a.mp4 -ss 00:37:04.300 -to 00:45:41.800 -c copy hosted-cluster.mp4

Using ffprobe, I was able to confirm that the original mp4 file uses the H.264 codec supported by the HTML5 standard.
////

This section introduces the essential concepts and terminology of OpenShift Hosted Control Planes (HCP) and describes the proof-of-concept (PoC) environment that you will deploy in the activities of this course.

_Watch the optional video and then read the introduction section._

WARNING: If you have issues watching the video embedded in this page, watch it directly on the https://videos.learning.redhat.com/media/hcp-on-bm-intro/1_79vnk220[Red Hat media space^], which requires the Red Hat VPN and an employee log in.

++++
<iframe type="text/javascript" src='https://cdnapisec.kaltura.com/p/2032581/embedPlaykitJs/uiconf_id/49478072?iframeembed=true&entry_id=1_c8kboedg' style="width: 768px; height: 432px" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" frameborder="0"></iframe>
++++

//Red Hat media space and ROL use different instances of Kaltura. The iframe uses the ROL instance.

== What are Hosted Control Planes?

Hosted Control Planes is a cloud-native architecture where the OpenShift control plane is decoupled from its data plane. The control planes of multiple OpenShift clusters run as pods on a single OpenShift cluster.

HCP uses the upstream project HyperShift and the MultiCluster Engine (MCE) operator. HCP can be co-hosted on an ACM hub cluster or on a dedicated OpenShift cluster.

HCP increases return on investment by using common hardware to run multiple control planes and allowing a higher server density. Without HCP, hardware resources are underutilized on master nodes, especially when you do not wish to share those nodes with user workloads.

We will see how Hosted control planes can increase ROI. In this example, there are 4 OpenShift clusters. One management cluster and 3 application clusters.

image::fig-1.svg[title="Multiple OpenShift clusters, without HCP"]

All four clusters are having 3 dedicated master nodes and a few infra and workers nodes. In this case, without HCP, total 40 nodes are required to serve 4 OpenShift clusters.

Now with hosted control planes feature: the control planes of all 3 clusters are running as pods in the management cluster. Infra and worker nodes remains same. The management cluster has 3 control plane + 3 infra nodes same as earlier. But, in application clusters, the 3 control plane nodes are not required. So, in total, 31 nodes are sufficient to have 4 OpenShift clusters, whereas without HCP, 40 nodes were required.

image::fig-2.svg[title="Multiple OpenShift clusters, using HCP"]

Letâ€™s deep dive into a sample HCP architecture. In HCP, the cluster on which control planes run is called the _host cluster_. In this architecture, the host cluster is same as the OpenShift management cluster which runs the ACM hub. The ACM, MCE, and HyperShift operators run on the host cluster, which is a standard OpenShift cluster with three 3 schedulable masters and 3 infra nodes.

image::fig-3.png[title="HCP architecture with single host/hub cluster"]

In continuation to the previous example, there are 3 application clusters, each one on its own namespace on the host cluster. HCP pods, api-server, auth-server, etcd, olm, and other control plane pods run in each of these namespaces. On the data plane side, the first cluster has AWS EC2 instances as workers; the second cluster has bare metal nodes running on their data-center as worker nodes; and the third cluster has OpenShift Virtualization VMs, hosted by the ACM hub cluster, as worker nodes.

Another architecture for HCP has a dedicated ACM hub cluster and multiple managed clusters acting as host clusters.

image::fig-4.png[title="HCP architecture with single hub cluster and multiple host clusters"]

This architecture offers greater scalability because the number of hosted clusters is not limited by the capacity of the ACM hub cluster. The hub cluster manages both host clusters and hosted clusters. On each host cluster, there is a separate instance of the MCE, which is not self managed, but it is managed by the ACM hub. The ACM hub also manages the data planes of each hosted cluster, which again can reside on different kinds of infrastructure, from IaaS cloud instances to physical servers.

== Why Hosted Control Planes ?

The following are a few use cases where Hosted Control Planes is a good fit:

Hybrid cloud adoption::
Deploy applications across multiple cloud providers or hybrid cloud environments.

Edge and IoT applications::
Edge computing and IoT applications that require a lightweight, flexible platform to manage distributed systems

OCP as a managed service::
Increase ROI by running multiple control planes on pods instead of dedicated nodes.
+
Offer OpenShift as a managed service to customers where customers do not need to manage the control plane.

Startups or fast growing organizations::
HCP clusters data plane can be created using OpenShift Virtualization.
+
Cluster creation and adding more clusters is faster and cheaper with HCP and OpenShift Virtualization VMs.

== Planing PoCs and Testing Hosted Control Planes

Most customers are planning to use bare metal servers, but they may not have enough physical servers available for a proof-of-concept (PoC), or may not be able to provide such servers in a timely manner.

You see, a text-book deployment of HCP requires 6 servers for the hub/host cluster alone (3 masters + 3 infra nodes) and additional servers for worker nodes of hosted clusters. Even if you attempt to use a compact cluster (3 schedulable masters and no infra nodes) you still require a minimum of five servers for creating a single hosted cluster with two nodes.

To work around availability of servers, and still perform a successful PoC, you can use RHEL virtualization, based on KVM and libvirt, to emulate multiple bare metal servers on a single physical server, or on a smaller number of servers that would be required to provide dedicated servers for a hub/host cluster + dedicated servers for worker nodes/data plane nodes.

image::diagram-full.svg[title="PoC environment for HCP using a single server and libvirt VMs"]

By following the activities in this course, you will first use a set of provided Ansible playbooks to:

* Configure the bare metal host and a helper services VM, to provide DHCP, BOOTP, and load balancer services.
* Configure a set of six libvirt VMs as a hub and host cluster.

Then you will use the OpenShift web console to:

* Configure an ACM infrastructure environment and add VMs as physical hosts to that environment.
* Create a hosted cluster using those VMs as worker nodes.

And you will use the OpenShift CLI to access the new hosted cluster, in addition to its own web console.

You will also experiment with different ways of provisioning your physical hosts and adding them to an infrastructure environment, including optional virtual BMC services to demonstrate the usage of managed server hardware as part of your HCP deployments.


